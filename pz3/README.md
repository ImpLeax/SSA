# Практична робота №3

## Налаштування Docker у середовищі WSL

Для виконання практичної роботи було використано Docker Desktop з інтеграцією у WSL. Процес налаштування включав наступні кроки:

1. **Встановлення Docker Desktop** на хостову машину (Windows).
2. **Активація інтеграції:** у налаштуваннях Docker Desktop перейшов у розділ **Settings → Resources → WSL Integration**.
3. **Вибір дистрибутиву:** увімкнув перемикач навпроти свого встановленого дистрибутиву (Ubuntu/WSL), що дозволило використовувати команду `docker` безпосередньо з терміналу WSL без необхідності встановлення окремого Docker Engine всередині Linux.

<img width="1576" height="900" alt="image" src="https://github.com/user-attachments/assets/693fc728-d33b-4a7c-a75b-c27a31d47987" />


---

## Завдання 3.1. Дослідження лімітів ресурсів (відкриті файли)

Метою завдання було дослідити механізм керування лімітами відкритих файлів (`ulimit`) усередині ізольованого Docker-контейнера та перевірити правила зміни м'яких (Soft) та жорстких (Hard) лімітів.

### 1. Запуск контейнера та перевірка початкових значень

Для експерименту було запущено контейнер на базі образу Ubuntu:

```bash
docker run -it ubuntu bash

```

Після входу в систему було перевірено поточні ліміти на кількість відкритих файлів (флаг `-n` або `-aS`/`-aH` для перегляду всіх лімітів):

* **Початковий ліміт:** `1048576` (як для м'якого, так і для жорсткого лімітів).

### 2. Експерименти зі зміною лімітів

У ході роботи виконувалися команди для зміни ліміту `ulimit -n`. Результати зафіксовано у таблиці:

| Команда | Результат | Пояснення |
| --- | --- | --- |
| `ulimit -n 3000` | Успішно | Ліміт встановлено на 3000. Команда без додаткових прапорців зазвичай змінює обидва ліміти (Soft і Hard) одночасно. |
| `ulimit -n 3001` | **Помилка (Operation not permitted)** | Спроба перевищити поточний жорсткий ліміт (3000). Користувач не може підняти ліміт вище встановленого Hard limit. |
| `ulimit -n 2000` | Успішно | Зниження ліміту до 2000. |
| `ulimit -n 3000` | **Помилка (Operation not permitted)** | Навіть якщо раніше ліміт був 3000, після його зниження до 2000 Hard limit також став 2000. Підняти його назад неможливо. |

### 3. Спроба використання sudo

При спробі обійти обмеження за допомогою `sudo ulimit -n` виникла помилка:
`bash: sudo: command not found`

**Причина:** Чисті Docker-образи (як-от `ubuntu:latest`) є максимально мінімізованими. У них відсутня утиліта `sudo`, оскільки за замовчуванням користувач у контейнері вже має права `root`, але навіть `root` обмежений правилами ядра та конфігурацією Docker-хоста щодо зміни жорстких лімітів.

---

### Висновки до завдання 3.1

На основі проведених експериментів підтверджено наступні властивості системних лімітів:

1. **Незворотність Hard Limit:** Якщо користувач (навіть root усередині контейнера) знижує жорсткий ліміт (`Hard Limit`), він не може підняти його назад у межах цієї ж сесії без перезапуску процесу/контейнера.
2. **Вплив на Soft Limit:** М'який ліміт (`Soft Limit`) — це фактичне обмеження для процесів, яке можна вільно змінювати в межах від 0 до значення `Hard Limit`.
3. **Ізоляція контейнера:** Docker-контейнер отримує початкові значення лімітів від Docker Daemon. Початкове значення `1048576` є стандартним для сучасних систем і дозволяє обробляти велику кількість файлових дескрипторів одночасно.

---

## Вивід терміналу (Log)

```bash
root@b246583d572e:/# ulimit -n
1048576
root@b246583d572e:/# ulimit -n 3000
root@b246583d572e:/# ulimit -aS | grep "open files"
open files                          (-n) 3000
root@b246583d572e:/# ulimit -aH | grep "open files"
open files                          (-n) 3000
root@b246583d572e:/# ulimit -n 3001
bash: ulimit: open files: cannot modify limit: Operation not permitted
root@b246583d572e:/# ulimit -n 2000
root@b246583d572e:/# ulimit -n
2000
root@b246583d572e:/# ulimit -n 3000
bash: ulimit: open files: cannot modify limit: Operation not permitted

```

## Завдання 3.2. Дослідження ліміту процесорного часу та аналіз продуктивності

Метою завдання було дослідити вплив ліміту процесорного часу (`ulimit -t`) на виконання процесів у Docker-контейнері та проаналізувати статистику продуктивності за допомогою утиліти `perf`.

### 1. Експеримент із лімітом CPU Time (`ulimit -t`)

Я запустив контейнер в інтерактивному режимі та встановив обмеження на максимальний час роботи процесора в секундах.

**Послідовність дій:**

1. Встановлено ліміт у 5 секунд: `ulimit -t 5`.
2. Запущено інтенсивний процес: `yes > /dev/null`.

**Результат:**

```bash
root@5f03bc51eb4b:/# ulimit -t 5
root@5f03bc51eb4b:/# yes > /dev/null
Killed

```

Через 5 секунд системного часу процес було автоматично завершено ядром (сигнал `SIGXCPU`), що підтверджує працездатність обмеження ресурсів на рівні окремого процесу в контейнері.

---

### 2. Аналіз продуктивності за допомогою `perf`

Для детального аналізу того, як процес використовує ресурси системи, було використано утиліту `perf stat`. Оскільки в середовищі WSL/Docker доступ до апаратних лічильників (PMU) часто обмежений, утиліта фокусується на програмних подіях.

**Команда:**

```bash
sudo perf stat yes > /dev/null

```

**Отримані метрики (фрагмент):**

* **task-clock:** ~8150 мсек (час, протягом якого процесор був зайнятий виконанням завдання).
* **CPUs utilized:** 1.034 (процес повністю завантажив одне ядро процесора).
* **page-faults:** 77 (мінімальна кількість помилок сторінок, оскільки `yes` майже не працює з пам'яттю).
* **user / sys:** Час виконання розподілився приблизно порівну між користувацьким режимом (3.95 сек) та системними викликами (4.19 сек).

> **Примітка:** У виводі спостерігається `<not supported>` для `cycles` та `instructions`. Це особливість роботи в WSL2, де віртуалізатор не прокидає апаратні лічильники продуктивності (Performance Monitoring Unit) всередину віртуальної машини без спеціальних налаштувань хоста.

---

### 3. Керування фоновими процесами в контейнері

Також було відпрацьовано механізм запуску та моніторингу процесів у фоновому режимі:

1. **Запуск контейнера в фоні:** `docker run -d --name test-container ubuntu sleep infinity`.
2. **Запуск процесу всередині:** `docker exec -d test-container yes > /dev/null`.
3. **Моніторинг:** за допомогою `docker top test-container` було зафіксовано PID процесу `yes` та рівень його навантаження на CPU.
4. **Завершення:** процес був примусово зупинений командою `docker exec test-container pkill yes`.

| Команда | Призначення |
| --- | --- |
| `docker top` | Перегляд запущених процесів усередині контейнера з їхніми PID. |
| `pkill` | Надсилання сигналу завершення всім процесам із вказаним іменем. |
| `perf stat` | Збір інтегральної статистики виконання програми. |

---

### Висновки до завдання 3.2

1. **Ефективність `ulimit -t`:** Дане обмеження є дієвим інструментом для запобігання ситуаціям, коли "зациклений" або надто важкий процес монополізує процесорний час.
2. **Особливості `perf` у WSL:** Хоча апаратні лічильники недоступні, `perf` залишається корисним для вимірювання часу виконання, перемикань контексту та розподілу навантаження між режимами `user` і `kernel`.
3. **Ізоляція та керування:** Docker дозволяє гнучко керувати процесами всередині контейнера (через `exec` та `top`) без необхідності входу в інтерактивну сесію.

## Завдання 3.3. Обробка перевищення ліміту розміру файлу (SIGXFSZ)

Метою цього завдання було написати програму на мові C, яка імітує кидання кубика та записує результати у файл, а також реалізувати коректну обробку сигналу `SIGXFSZ`, який виникає при спробі вийти за межі встановленого системного ліміту на розмір файлу.

### 1. Програмна реалізація

У програмі реалізовано генерацію випадкових чисел (від 1 до 6) та циклічний запис результатів у текстовий файл. Ключовою особливістю є використання функції `signal()` для перехоплення помилки перевищення розміру.

**Повний код програми:**

```c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <signal.h>
#include <unistd.h>

// Обробник сигналу перевищення ліміту розміру файлу
void sigxfsz_handler(int sig) {
    printf("\nFile size limit exceeded! Program stopped.\n");
    exit(1);
}

int imitate_throw() {
    return 1 + rand() % 6;
}

int main() {
    srand(time(NULL));

    // Реєстрація обробника для сигналу SIGXFSZ
    signal(SIGXFSZ, sigxfsz_handler);

    FILE *file = fopen("throw_results.txt", "w");
    if (file == NULL) {
        printf("Cannot open file!\n");
        return 1;
    }

    int i = 0;
    while (i < 10000) {
        // Запис результатів у файл
        fprintf(file, "Throw #%d: %d\n", i, imitate_throw());
        i++;
    }

    fclose(file);
    return 0;
}

```

---

### 2. Експеримент із системним лімітом `ulimit -f`

Для перевірки роботи обробника було використано команду `ulimit -f`, яка встановлює максимальний розмір файлів, що може створювати поточний процес (ліміт вказується в блоках, зазвичай по 1024 байти).

**Хід експерименту:**

1. **Компіляція:**
```bash
gcc -Wall zd3.c -o prog

```


2. **Встановлення жорсткого ліміту:**
Командою `ulimit -f 2` я обмежив максимальний розмір файлу до 2 блоків (приблизно 2 КБ).
3. **Запуск:**
При спробі записати 10,000 рядків файл швидко досяг межі у 2 КБ. Операційна система надіслала процесу сигнал `SIGXFSZ`.

**Вивід терміналу:**

```bash
impleax@Impleax:~/SSA/pz3/zd3$ ulimit -f 2
impleax@Impleax:~/SSA/pz3/zd3$ ./prog

File size limit exceeded! Program stopped.

```

---

### 3. Аналіз механізму роботи

1. **Сигнал SIGXFSZ:** Це спеціальний сигнал (Signal eXceed File SiZe), який ядро надсилає процесу, коли той намагається виконати операцію запису (`write`), що призведе до перевищення ліміту `RLIMIT_FSIZE`.
2. **Роль обробника:** Без власного обробника програма просто б "впала" (terminated) без жодних пояснень. Завдяки функції `sigxfsz_handler` ми змогли вивести зрозуміле повідомлення та коректно завершити роботу програми.
3. **Параметри `ulimit`:** Значення `2` у команді `ulimit -f 2` виявилося достатнім для того, щоб програма встигла записати лише декілька десятків рядків перед спрацюванням захисту.

### Висновки до завдання 3.3

1. **Керування ресурсами:** Використання `ulimit` дозволяє адміністраторам та розробникам обмежувати споживання дискового простору процесами, що критично для стабільності серверних систем.
2. **Надійність ПЗ:** Професійне системне програмне забезпечення повинно передбачати обробку таких сигналів, щоб запобігти втраті даних або непередбачуваній поведінці системи при вичерпанні лімітів.

## Завдання 3.4. Дослідження ліміту процесорного часу (SIGXCPU)

Метою цього завдання було написати програму на мові C, яка імітує лотерейний розіграш у нескінченному циклі, та дослідити механізм примусового завершення процесу при вичерпанні ліміту часу ЦП (`max CPU time`).

### 1. Опис алгоритму

Програма виконує генерацію двох типів лотерейних комбінацій:

* **7 із 49:** вибір семи унікальних чисел.
* **6 із 36:** вибір шести унікальних чисел.

Для забезпечення унікальності чисел використано алгоритм, схожий на тасування Фішера-Йейтса: створюється масив усіх можливих чисел, і на кожному кроці вибирається випадковий елемент, який міняється місцями з поточним. Це гарантує відсутність дублікатів без необхідності повторних перевірок.

### 2. Обробка сигналу SIGXCPU

Оскільки програма містить нескінченний цикл `while (1)`, вона потенційно може повністю завантажити ядро процесора на невизначений час. Для безпеки було реалізовано:

1. **Реєстрацію обробника:** функція `handle_sigxcpu` перехоплює сигнал від ОС.
2. **Графічне завершення:** замість раптового "вильоту", програма виводить інформаційне повідомлення про вичерпання ліміту та завершується з кодом `0`.

**Код обробника:**

```c
void handle_sigxcpu(int signum) {
    printf("\n\n[SIGXCPU Signal] CPU time limit exceeded!\n");
    printf("Program terminated gracefully. Thanks for playing.\n");
    exit(0);
}

```

---

### 3. Запуск та результати експерименту

Для перевірки було встановлено "м'який" ліміт процесорного часу в 1 секунду за допомогою команди `ulimit`.

**Послідовність команд:**

```bash
gcc -Wall zd4.c -o prog
ulimit -St 1
./prog

```

**Результат у терміналі:**
Програма встигла згенерувати сотні комбінацій за одну секунду, після чого ядро Linux надіслало сигнал `SIGXCPU`, і спрацював наш обробник:

```text
...
32 34 21 33 15 18 44 | 19 13 25 10 6 34 |
45 42 47 30 4 24 13 | 29 6 15 19 14 24 |

[SIGXCPU Signal] CPU time limit exceeded!
Program terminated gracefully. Thanks for playing.

```

---

### Висновки до завдання 3.4

1. **Контроль ресурсів:** Ліміт `CPU time` (на відміну від реального часу `wall clock time`) враховує лише той час, коли процесор був безпосередньо зайнятий обчисленнями нашої програми.
2. **Захист системи:** Обмеження `ulimit -t` є критично важливим для запобігання ситуаціям, коли через помилку в коді (нескінченний цикл) один процес "з'їдає" всі ресурси сервера.
3. **Сигнали як інструмент керування:** Використання `SIGXCPU` дозволяє програмісту реалізувати логіку збереження проміжних результатів або коректного закриття файлів перед тим, як операційна система примусово зупинить виконання.

## Завдання 3.5. Копіювання файлів із використанням системних викликів та обробкою SIGXFSZ

Метою цього завдання було розробити утиліту для копіювання файлів на мові C, використовуючи низькорівневі системні виклики (`open`, `read`, `write`), та забезпечити надійну перевірку аргументів і системних лімітів.

### 1. Реалізація програми

Програма виконує копіювання вмісту одного файлу в інший блок за блоком (розмір буфера — 4096 байт).

**Ключові особливості:**

* **Валідація аргументів:** перевірка `argc != 3` для впевненості, що користувач вказав шлях до джерела та призначення.
* **Низькорівневий доступ:** замість стандартної бібліотеки `stdio.h` (fopen/fwrite) використано системні виклики ядра для більшого контролю над дескрипторами файлів.
* **Прапорці доступу:** файл призначення відкривається з правами `O_WRONLY | O_CREAT | O_TRUNC`, що дозволяє створити файл, якщо його не існує, або очистити, якщо він вже є.
* **Обробка помилок:** програма детально інформує, якщо файл не вдалося відкрити для читання чи запису.

**Фрагмент коду (основний цикл копіювання та обробник):**

```c
void handle_sigxfsz(int signum) {
    printf("\n[SIGXFSZ Signal] File size limit exceeded!\n");
    exit(1);
}

// ... у main ...
while ((bytes_read = read(fd_in, buffer, sizeof(buffer))) > 0) {
    bytes_written = write(fd_out, buffer, bytes_read);
    if (bytes_written == -1 && errno == EFBIG) {
        printf("\nWrite error: File size limit exceeded!\n");
        break;
    }
}

```

---

### 2. Експериментальна перевірка

Для тестування було створено великий файл і встановлено штучне обмеження на запис.

**Крок 1: Створення тестового файлу (5 МБ)**
Використано утиліту `dd` для генерації файлу з випадковими даними:

```bash
dd if=/dev/urandom of=large_file.bin bs=1M count=5

```

**Крок 2: Встановлення ліміту та тестування копіювання**
Я встановив "м'який" ліміт на розмір файлу у 2048 блоків (2 МБ) і спробував скопіювати 5-мегабайтний файл.

**Вивід у терміналі:**

```bash
impleax@Impleax:~/SSA/pz3/zd5$ ulimit -Sf 2048
impleax@Impleax:~/SSA/pz3/zd5$ ./prog large_file.bin copy_file.bin

[SIGXFSZ Signal] File size limit exceeded!

```

**Крок 3: Перевірка валідації**
Також перевірено роботу програми при вказанні неіснуючого файлу:

```bash
impleax@Impleax:~/SSA/pz3/zd5$ ./prog test.txt test2.txt
Cannot open file test.txt for reading

```

---

### Висновки до завдання 3.5

1. **Системні виклики vs Бібліотечні функції:** використання `read/write` дозволяє програмі ефективніше взаємодіяти з ядром, що важливо для системних утиліт копіювання.
2. **Обробка сигналів:** програма успішно перехоплює сигнал `SIGXFSZ`. Це критично важливо для утиліт копіювання, щоб вони не залишали пошкоджені файли без повідомлення користувача про причину зупинки.
3. **Безпека:** реалізована перевірка прав доступу та наявності файлів запобігає некоректному завершенню роботи (Segmentation fault) та інформує користувача про конкретну проблему.

## Завдання 3.6. Дослідження ліміту сегмента стека (Stack Segment Size)

Метою цього завдання було продемонструвати вплив обмеження розміру стека на роботу програми. Оскільки стек використовується для зберігання локальних змінних та адрес повернення з функцій, найпростіший спосіб його вичерпати — використати глибоку рекурсію.

### 1. Особливості реалізації (Alternate Signal Stack)

При вичерпанні стека операційна система надсилає процесу сигнал **SIGSEGV** (Segmentation Fault). Проте виникає проблема: для запуску функції-обробника сигналу також потрібне місце на стеку. Якщо стек вже переповнений, обробник не зможе запуститися, і програма просто "впаде".

Для вирішення цієї проблеми у програмі використано **альтернативний стек сигналів**:

1. **`sigaltstack`**: виділяє окрему область пам'яті в Купі (Heap) спеціально для обробки сигналів.
2. **`SA_ONSTACK`**: прапорець у `sigaction`, який вказує системі запускати обробник `SIGSEGV` саме на цьому альтернативному стеку.

**Фрагмент коду програми:**

```c
void recursive_function(int depth) {
    char buffer[1024]; // Кожен виклик споживає 1 КБ стека
    if (depth % 1000 == 0) printf("Current recursion depth: %d\n", depth);
    recursive_function(depth + 1);
}

int main() {
    // Налаштування альтернативного стека для обробки сигналів
    stack_t alt_stack;
    alt_stack.ss_sp = malloc(SIGSTKSZ);
    alt_stack.ss_size = SIGSTKSZ;
    alt_stack.ss_flags = 0;
    sigaltstack(&alt_stack, NULL);

    struct sigaction sa;
    sa.sa_handler = handle_sigsegv;
    sa.sa_flags = SA_ONSTACK; // Використовувати альтернативний стек
    sigaction(SIGSEGV, &sa, NULL);

    recursive_function(1);
    return 0;
}

```

---

### 2. Експеримент із лімітами `ulimit -s`

Я перевірив роботу програми при стандартному ліміті та при його штучному зменшенні.

**Етап 1: Стандартний ліміт (8192 КБ)**
За замовчуванням система виділяє 8 МБ під стек. Програма змогла досягти глибини рекурсії понад 7000 викликів (кожен з яких займав понад 1 КБ), перш ніж стався переповнення.

**Етап 2: Зменшений ліміт (1024 КБ)**
Командою `ulimit -Ss 1024` я зменшив м'який ліміт стека до 1 МБ.

**Порівняння результатів:**

| Ліміт стека | Глибина рекурсії до краху | Результат |
| --- | --- | --- |
| **8192 KB** | ~7500-7800 | Виведено повідомлення через `SIGSEGV` |
| **1024 KB** | < 1000 | Моментальний крах із виводом обробника |

**Вивід терміналу:**

```bash
impleax@Impleax:~/SSA/pz3/zd6$ ulimit -Ss 1024
impleax@Impleax:~/SSA/pz3/zd6$ ./prog
Starting infinite recursion to demonstrate stack overflow...

[SIGSEGV Signal] Stack segment size limit exceeded!

```

---

### Висновки до завдання 3.6

1. **Стек — обмежений ресурс:** На відміну від Купи (Heap), розмір якої обмежений лише оперативною пам'яттю, стек кожного потоку має фіксований ліміт. Його легко вичерпати при неконтрольованій рекурсії або створенні занадто великих локальних масивів.
2. **Важливість `sigaltstack`:** Без використання альтернативного стека неможливо "красиво" обробити помилку переповнення стека (Stack Overflow), оскільки системі немає де розмістити кадр функції-обробника.
3. **Керування лімітами:** Утиліта `ulimit -s` дозволяє розробникам тестувати стійкість програм до обмежених ресурсів та запобігати аварійному завершенню всієї системи через один некоректний процес.

## Завдання за варіантами (Варіант 2) — Дослідження ліміту відкритих сокетів

Метою цього завдання було дослідити вплив обмеження на кількість відкритих файлових дескрипторів (`ulimit -n`) на роботу мережевого сервера та перевірити здатність програми коректно обробляти вичерпання цього ресурсу.

### 1. Опис реалізації

Я написав TCP-сервер на мові C, який слухає порт **8080**. Основна особливість програми — обробка помилок у циклі `accept()`.

**Логіка програми:**

* Сервер створює слухаючий сокет і переходить у режим очікування з'єднань.
* При кожному новому підключенні сервер отримує новий файловий дескриптор.
* Якщо системний ліміт вичерпано, системний виклик `accept()` повертає помилку, а змінна `errno` набуває значення `EMFILE` (Too many open files).
* Програма фіксує цей момент, виводить загальну кількість успішних з'єднань і завершує роботу.

---

### 2. Експеримент та аналіз результатів

Для тестування було встановлено м'який ліміт у **50** відкритих файлів і запущено скрипт для масового підключення клієнтів за допомогою `nc` (netcat).

**Команди для відтворення:**

```bash
gcc -Wall zd_v2.c -o prog
ulimit -Sn 50  # Встановлення ліміту на 50 дескрипторів
./prog
# В іншому терміналі:
for i in {1..100}; do nc localhost 8080 & done

```

**Результат у терміналі:**
Сервер зупинився на позначці **46** активних з'єднань.

**Чому саме 46?**
Ліміт `ulimit -n 50` обмежує загальну кількість файлових дескрипторів для процесу. У нашому випадку вони розподілилися так:

1. **FD 0, 1, 2:** Стандартні потоки введення, виведення та помилок (3 шт).
2. **FD 3:** Слухаючий сокет сервера (1 шт).
3. **FD 4–49:** З'єднання, прийняті через `accept` (46 шт).
**Разом:** $3 + 1 + 46 = 50$ дескрипторів.

---

### 3. Висновки до завдання

1. **Ліміти дескрипторів:** У Linux сокети є файлами. Кожне нове з'єднання потребує нового дескриптора. Якщо сервер не закриває з'єднання або має занадто низький ліміт `ulimit -n`, він перестане приймати нових клієнтів (DoS стан).
2. **Обробка EMFILE:** Правильна обробка коду помилки `EMFILE` дозволяє серверу "впасти" контрольовано або почати відхиляти запити, замість того, щоб піти в нескінченний цикл помилок, що могло б призвести до 100% завантаження ЦП.
3. **Конфігурація високонавантажених систем:** Для реальних серверів (наприклад, Nginx або бази даних) значення `ulimit -n` зазвичай встановлюють у десятки або сотні тисяч, щоб уникнути обмежень, продемонстрованих у цій роботі.

---

### Загальний підсумок практичної роботи

Протягом роботи було проведено комплексне дослідження системних лімітів (ресурсів) у середовищі WSL/Ubuntu. Ми навчилися:

* Керувати лімітами через `ulimit`.
* Аналізувати поведінку процесів при досягненні лімітів пам'яті, часу ЦП, розміру файлів та кількості сокетів.
* Програмно перехоплювати сигнали (`SIGXCPU`, `SIGXFSZ`, `SIGSEGV`), що є критично важливим для написання відмовостійкого системного ПЗ.


